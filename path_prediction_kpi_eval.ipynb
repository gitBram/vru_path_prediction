{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "source": [
                "def __return_waypoints_ind():\n",
                "    d = np.array([\n",
                "    [ 65, -36],\n",
                "    [ 56, -21],\n",
                "    [ 66, -46],\n",
                "    [ 58, -48],\n",
                "    [ 67, -29],\n",
                "    [ 61, -16],\n",
                "    [ 45, -32],\n",
                "    [ 71, -43],\n",
                "    # [ 80, -52],\n",
                "    # [ 68, -58],\n",
                "    [ 65, -54],\n",
                "    [ 48, -20],\n",
                "    [ 64, -21],\n",
                "    [ 46, -14]])\n",
                "    return d\n",
                "\n",
                "%load_ext autoreload\n",
                "%autoreload 2"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "source": [
                "import os, sys\n",
                "from helpers.highlevel_sceneloader import HighLevelSceneLoader\n",
                "from predictors.dataset_creator import TFDataSet\n",
                "import tensorflow as tf\n",
                "from predictors.dl_trainer import DLTrainer \n",
                "from predictors.extended_predictor import extended_predictor \n",
                "import matplotlib.pyplot as plt\n",
                "import pickle\n",
                "from helpers.graph import Graph\n",
                "import numpy as np\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "from datetime import datetime\n",
                "from helpers.accuracy_functions import *\n",
                "import csv\n",
                "import math\n",
                "from tqdm import tqdm\n",
                "\n",
                "\n",
                "''' set some parameters '''\n",
                "# Model parameters\n",
                "LSTM_LAYER_SIZE = 64\n",
                "DENSE_LAYER_SIZE = 128\n",
                "NUM_LSTM_LAYERS = 2\n",
                "NUM_DENSE_LAYERS = 2\n",
                "VARIABLE_INPUT_LENGTH = False\n",
                "\n",
                "# Dataset\n",
                "SEQ_IN_LEN = 3\n",
                "SEQ_OUT_LEN = 8\n",
                "NOISE_STD = .3\n",
                "N_REPEATS = 1\n",
                "\n",
                "BATCH_SIZE = 5\n",
                "LENGTH_STRIDE = 2\n",
                "\n",
                "\n",
                "# Training parameters\n",
                "MAX_EPOCHS = 100\n",
                "PATIENCE = 5\n",
                "\n",
                "# For graph\n",
                "GRAPH_DIST_THRESH = 4\n",
                "\n",
                "''' get the data '''\n",
                "ROOT = os.getcwd()\n",
                "\n",
                "rel_p_img_b = 'helpers/analysed_vars_storage/img_bounds.xml'\n",
                "rel_p_dests = 'helpers/analysed_vars_storage/destination_locations.xml'\n",
                "p_img_bounds = os.path.join(ROOT, rel_p_img_b)\n",
                "p_dest_locs = os.path.join(ROOT, rel_p_dests)\n",
                "\n",
                "#TODO: older version of OpenTraj needed: \"git checkout d249ba6951dd0f54b532fbe2ca6edc46b0d7093f\"\n",
                "opentraj_root = os.path.join(ROOT, 'OpenTraj')\n",
                "root_datasets = os.path.join(ROOT, 'data/path_data')\n",
                "sys.path.append(opentraj_root) # add package to pythonpath\n",
                "\n",
                "scene_data = HighLevelSceneLoader(p_img_bounds, p_dest_locs)\n",
                "scene_data.load_ind(root_datasets, 7, 17)\n",
                "\n",
                "\n",
                "''' create the graph instance '''    \n",
                "interest_points = __return_waypoints_ind()\n",
                "g = Graph.from_matrices(interest_points, scene_data.destination_matrix, GRAPH_DIST_THRESH, .05)\n",
                "\n",
                "df_signals = scene_data.df_to_lst_realxy_mats()\n",
                "g.analyse_multiple_full_signals(df_signals, add_to_trams_mat=True)\n",
                "\n",
                "''' time to create df datasets '''\n",
                "extra_features_dict = {\n",
                "    \"all_points\": None,\n",
                "    \"all_destinations\": None,\n",
                "    \"n_destinations\": 5,\n",
                "    \"n_points\": 5,\n",
                "    \"n_connected_points_after\" : 3\n",
                "}\n",
                "\n",
                "# Load data in order to not need to do calculations again\n",
                "# with open(\"data/pickle/ds_creation_d/ds_7to17_inputLabels5_6.pickle\", 'rb') as handle: #\"data/pickle/ds_creation_d/bs1.pickle\"\n",
                "#     my_ds_creation_dict = pickle.load(handle)\n",
                "\n",
                "my_ds = TFDataSet.init_as_fixed_length(scene_data.traj_dataframe, graph=g, var_in_len=VARIABLE_INPUT_LENGTH, length_stride=LENGTH_STRIDE,\n",
                "scale_list=[\"pos_x\", \"pos_y\"], seq_in_length=SEQ_IN_LEN, label_length=SEQ_OUT_LEN,\n",
                "extra_features_dict=extra_features_dict, noise_std=NOISE_STD, \n",
                "n_repeats=N_REPEATS, batch_size=BATCH_SIZE, save_folder = \"data/pickle/ds_creation_d/ds_7to17_inputLabels3_8.pickle\") #, ds_creation_dict=my_ds_creation_dict\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "WARNING:tensorflow:From /home/bram/anaconda3/envs/thesis_basic/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
                        "Instructions for updating:\n",
                        "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# ''' time for some model training '''\n",
                "# # BASIC TRAINER\n",
                "# my_trainer = DLTrainer(max_epochs=MAX_EPOCHS, patience=PATIENCE)\n",
                "# my_trainer.LSTM_one_shot_predictor_named_i(my_ds, LSTM_LAYER_SIZE, DENSE_LAYER_SIZE, \n",
                "# NUM_LSTM_LAYERS, NUM_DENSE_LAYERS, extra_features=[\"all_destinations\"], var_time_len=VARIABLE_INPUT_LENGTH)\n",
                "\n",
                "# save_path = \"data/model_weights/checkpoints/cp_path_pred_kpi/in5out3/with_dest.pickle\"\n",
                "\n",
                "# # cp5 contains with none axis\n",
                "# try:\n",
                "#     # first do one epoch of training in order to initialize weights\n",
                "#     # my_trainer.compile_and_fit(my_ds, 'data/model_weights/checkpoints/bin/test_cp1.ckpt', test_fit=True)\n",
                "#     my_trainer.load_weights(save_path)\n",
                "# except:\n",
                "#     my_trainer.compile_and_fit(my_ds, save_path)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# my_predictor = extended_predictor(g, my_trainer, 1)\n",
                "\n",
                "# nxt_unsc, nxt_sc = my_ds.example_dict(\"test\", \"in_xy\")\n",
                "\n",
                "# output, output_s = my_trainer.predict_dict(nxt_unsc[0], False)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# for i in range(1):\n",
                "#     fig1, ax1 = plt.subplots()\n",
                "#     scene_data.plot_on_image([nxt_sc[0][\"in_xy\"], nxt_sc[1], output_s], \n",
                "#     save_path='data/images/final_notebook/example_prediction.png', ms = [6, 1, 3], ax=ax1, \n",
                "#     colors=[\"green\", \"blue\", \"yellow\"], axes_labels=[\"input\", \"label\", \"output\"])\n",
                "    \n",
                "#     dest_locs = nxt_sc[0][\"all_destinations\"][i][:, 0:2]\n",
                "#     dest_probs = nxt_sc[0][\"all_destinations\"][i][:, 2:3]\n",
                "    \n",
                "#     scene_data.plot_dest_probs(dest_locs, dest_probs, 2, 200,\n",
                "#     ax = ax1)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# # Calculate KPIs\n",
                "# it_ds = iter(my_ds.tf_ds_dict[\"test\"])\n",
                "\n",
                "# for ds_entry in it_ds:\n",
                "#     in_batch, output = ds_entry\n",
                "\n",
                "#     prediction_batch, prediction_batch_scaled = my_trainer.predict_dict(in_batch, False)\n",
                "\n",
                "#     kpi_val, c, nc = batch_kpi(avg_displacement_error, in_batch[\"labels\"], prediction_batch_scaled, 2)\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "source": [
                "# train the networks on the available data\n",
                "# included\n",
                "n_in_future = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
                "n_in_future = [5]\n",
                "percentage_of_path_avail = [.2, .3, .4, .5, .6, .7, .8, .9, 1.]\n",
                "num_input_steps = [2,3,4,5,-1] #needs new network trained every time\n",
                "num_output_steps = [3] #needs new network trained every time\n",
                "dests_included = [True]\n",
                "n_dense_layers = [2]\n",
                "n_lstm_layers = [2]\n",
                "dense_layer_sizes = [32, 128]\n",
                "lstm_layer_sizes = [32, 128]\n",
                "# not included\n",
                "\n",
                "n_conn_points_incl = [False]\n",
                "all_points_incl = [False]\n",
                "\n"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "# my_trainer = DLTrainer(max_epochs=1, patience=PATIENCE)\n",
                "# my_trainer.LSTM_one_shot_predictor_named_i(my_ds, LSTM_LAYER_SIZE, DENSE_LAYER_SIZE, \n",
                "# NUM_LSTM_LAYERS, NUM_DENSE_LAYERS, extra_features=[\"all_destinations\", \"n_connected_points_after\"], var_time_len=VARIABLE_INPUT_LENGTH, size_dict=my_ds.size_dict)\n",
                "# my_trainer.compile_and_fit2(my_ds.tf_ds_dict[\"train\"], my_ds.tf_ds_dict[\"val\"], save_path=\"save_path.pickle\")"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "source": [
                "\n",
                "# set up the csv writer\n",
                "csv_headers = [\"n\", \"ADE\", \"FDE\", \"counter\", \"not_counter\", \"num_in_steps\", \"num_out_steps\", \"dests_included\", \"all_points_included\", \"n_conn_points_included\", \"num_lstm_layers\", \"num_dense_layers\", \"lstm_layer_size\", \"dense_layer_size\"]\n",
                "csv_folder_path = \"data/results/destination_pred\"\n",
                "filename = 'results_' + datetime.now().strftime(\"%d_%m_%Y__%H_%M\") + \".csv\"\n",
                "full_path = os.path.join(csv_folder_path, filename)\n",
                "\n",
                "with open(full_path, 'w', newline='\\n') as csvfile:\n",
                "    my_writer = csv.writer(csvfile, delimiter=',')\n",
                "    my_writer.writerow(csv_headers)\n",
                "\n",
                "# Count entries in the big data set\n",
                "# num_training_samples = 0\n",
                "# for entry in iter(my_ds.tf_ds_dict[\"train\"]):\n",
                "#     num_training_samples+=1\n",
                "# num_val_samples = 0\n",
                "# for entry in iter(my_ds.tf_ds_dict[\"val\"]):\n",
                "#     num_val_samples+=1\n",
                "\n",
                "for n_dense in n_dense_layers:  \n",
                "    for n_lstm in n_lstm_layers:\n",
                "        for dest_included in dests_included:\n",
                "            for conn_point in n_conn_points_incl:   \n",
                "                for all_points in all_points_incl:\n",
                "                    for dense_layer_size in dense_layer_sizes:\n",
                "                        for lstm_layer_size in lstm_layer_sizes:\n",
                "                            ''' TRAIN THE MODEL '''\n",
                "                            # # Get the reduced training sets\n",
                "                            # smaller_train_ds = my_ds.tf_ds_dict[\"train\"].take(math.ceil(num_training_samples*path_percentage))\n",
                "                            # smaller_val_ds = my_ds.tf_ds_dict[\"val\"].take(math.ceil(num_val_samples*path_percentage))\n",
                "\n",
                "                            # Create the model instance\n",
                "                            feat_list = []\n",
                "                            if dest_included:\n",
                "                                feat_list.append(\"all_destinations\")\n",
                "                            if conn_point:\n",
                "                                feat_list.append(\"n_connected_points_after\")\n",
                "                            \n",
                "                            my_trainer = DLTrainer(max_epochs=MAX_EPOCHS, patience=PATIENCE)\n",
                "                            my_trainer.LSTM_one_shot_predictor_named_i(my_ds, LSTM_LAYER_SIZE, DENSE_LAYER_SIZE, \n",
                "                            n_lstm, n_dense, extra_features=feat_list, var_time_len=VARIABLE_INPUT_LENGTH, size_dict=my_ds.size_dict)\n",
                "\n",
                "                            folder_path = \"data/model_weights/checkpoints/cp_path_pred_kpi/%s\" % (datetime.now().strftime(\"%d_%m_%Y__%H_%M\"))\n",
                "                            save_path = os.path.join(folder_path, \"dest%sconnp%sallp%s.pickle\" % (dest_included, conn_point, all_points))            \n",
                "                            if not os.path.exists(folder_path):\n",
                "                                os.mkdir(folder_path)\n",
                "                            my_trainer.compile_and_fit2(my_ds.tf_ds_dict[\"train\"], my_ds.tf_ds_dict[\"val\"], save_path=save_path)\n",
                "\n",
                "                            ''' GET KPIs FOR THIS MODEL '''   \n",
                "                            print(\"Starting kpi calculation...\")    \n",
                "                            for n in tqdm(n_in_future):       \n",
                "                                ade, fde, c, nc = tf_ds_kpi(my_ds.tf_ds_dict[\"test\"], \"labels\", my_trainer, n, \n",
                "                                VARIABLE_INPUT_LENGTH)\n",
                "                                \n",
                "                                # Write them away for later analysis\n",
                "                                line = [n, ade, fde, c, nc, SEQ_IN_LEN, SEQ_OUT_LEN, dest_included, all_points, conn_point, n_lstm, n_dense, lstm_layer_size, dense_layer_size]\n",
                "\n",
                "                                with open(full_path, 'a', newline='\\n') as csvfile:\n",
                "                                    my_writer = csv.writer(csvfile, delimiter=',')\n",
                "                                    my_writer.writerow(line)\n",
                "                                "
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "5\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='flatten/Reshape:0', description=\"created by layer 'flatten'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
                        "Epoch 1/100\n",
                        "1445/1445 [==============================] - 20s 11ms/step - loss: 0.0965 - mean_absolute_error: 0.2155 - val_loss: 0.0805 - val_mean_absolute_error: 0.2079\n",
                        "\n",
                        "Epoch 00001: val_loss improved from inf to 0.08049, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 0 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0805.\n",
                        "Epoch 2/100\n",
                        "1445/1445 [==============================] - 17s 11ms/step - loss: 0.0290 - mean_absolute_error: 0.1227 - val_loss: 0.0493 - val_mean_absolute_error: 0.1494\n",
                        "\n",
                        "Epoch 00002: val_loss improved from 0.08049 to 0.04933, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 1 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0493.\n",
                        "Epoch 3/100\n",
                        "1445/1445 [==============================] - 16s 11ms/step - loss: 0.0212 - mean_absolute_error: 0.1045 - val_loss: 0.0415 - val_mean_absolute_error: 0.1362\n",
                        "\n",
                        "Epoch 00003: val_loss improved from 0.04933 to 0.04145, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 2 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0415.\n",
                        "Epoch 4/100\n",
                        "1445/1445 [==============================] - 17s 11ms/step - loss: 0.0199 - mean_absolute_error: 0.1004 - val_loss: 0.0381 - val_mean_absolute_error: 0.1245\n",
                        "\n",
                        "Epoch 00004: val_loss improved from 0.04145 to 0.03810, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 3 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0381.\n",
                        "Epoch 5/100\n",
                        "1445/1445 [==============================] - 16s 11ms/step - loss: 0.0189 - mean_absolute_error: 0.0982 - val_loss: 0.0437 - val_mean_absolute_error: 0.1473\n",
                        "\n",
                        "Epoch 00005: val_loss did not improve from 0.03810\n",
                        "No alternative save happened on for epoch 4\n",
                        "Epoch 6/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0184 - mean_absolute_error: 0.0968 - val_loss: 0.0400 - val_mean_absolute_error: 0.1426\n",
                        "\n",
                        "Epoch 00006: val_loss did not improve from 0.03810\n",
                        "No alternative save happened on for epoch 5\n",
                        "Epoch 7/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0176 - mean_absolute_error: 0.0944 - val_loss: 0.0355 - val_mean_absolute_error: 0.1248\n",
                        "\n",
                        "Epoch 00007: val_loss improved from 0.03810 to 0.03545, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 6 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0355.\n",
                        "Epoch 8/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0169 - mean_absolute_error: 0.0924 - val_loss: 0.0368 - val_mean_absolute_error: 0.1251\n",
                        "\n",
                        "Epoch 00008: val_loss did not improve from 0.03545\n",
                        "No alternative save happened on for epoch 7\n",
                        "Epoch 9/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0166 - mean_absolute_error: 0.0910 - val_loss: 0.0336 - val_mean_absolute_error: 0.1187\n",
                        "\n",
                        "Epoch 00009: val_loss improved from 0.03545 to 0.03364, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 8 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0336.\n",
                        "Epoch 10/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0162 - mean_absolute_error: 0.0905 - val_loss: 0.0334 - val_mean_absolute_error: 0.1214\n",
                        "\n",
                        "Epoch 00010: val_loss improved from 0.03364 to 0.03343, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 9 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0334.\n",
                        "Epoch 11/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0160 - mean_absolute_error: 0.0894 - val_loss: 0.0332 - val_mean_absolute_error: 0.1218\n",
                        "\n",
                        "Epoch 00011: val_loss improved from 0.03343 to 0.03320, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 10 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0332.\n",
                        "Epoch 12/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0155 - mean_absolute_error: 0.0878 - val_loss: 0.0370 - val_mean_absolute_error: 0.1310\n",
                        "\n",
                        "Epoch 00012: val_loss did not improve from 0.03320\n",
                        "No alternative save happened on for epoch 11\n",
                        "Epoch 13/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0155 - mean_absolute_error: 0.0880 - val_loss: 0.0330 - val_mean_absolute_error: 0.1190\n",
                        "\n",
                        "Epoch 00013: val_loss improved from 0.03320 to 0.03303, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 12 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0330.\n",
                        "Epoch 14/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0150 - mean_absolute_error: 0.0863 - val_loss: 0.0305 - val_mean_absolute_error: 0.1122\n",
                        "\n",
                        "Epoch 00014: val_loss improved from 0.03303 to 0.03053, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 13 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0305.\n",
                        "Epoch 15/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0145 - mean_absolute_error: 0.0845 - val_loss: 0.0325 - val_mean_absolute_error: 0.1179\n",
                        "\n",
                        "Epoch 00015: val_loss did not improve from 0.03053\n",
                        "No alternative save happened on for epoch 14\n",
                        "Epoch 16/100\n",
                        "1445/1445 [==============================] - 20s 13ms/step - loss: 0.0141 - mean_absolute_error: 0.0832 - val_loss: 0.0311 - val_mean_absolute_error: 0.1131\n",
                        "\n",
                        "Epoch 00016: val_loss did not improve from 0.03053\n",
                        "No alternative save happened on for epoch 15\n",
                        "Epoch 17/100\n",
                        "1445/1445 [==============================] - 20s 14ms/step - loss: 0.0138 - mean_absolute_error: 0.0825 - val_loss: 0.0297 - val_mean_absolute_error: 0.1102\n",
                        "\n",
                        "Epoch 00017: val_loss improved from 0.03053 to 0.02971, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 16 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0297.\n",
                        "Epoch 18/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0137 - mean_absolute_error: 0.0822 - val_loss: 0.0304 - val_mean_absolute_error: 0.1132\n",
                        "\n",
                        "Epoch 00018: val_loss did not improve from 0.02971\n",
                        "No alternative save happened on for epoch 17\n",
                        "Epoch 19/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0134 - mean_absolute_error: 0.0809 - val_loss: 0.0360 - val_mean_absolute_error: 0.1327\n",
                        "\n",
                        "Epoch 00019: val_loss did not improve from 0.02971\n",
                        "No alternative save happened on for epoch 18\n",
                        "Epoch 20/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0136 - mean_absolute_error: 0.0813 - val_loss: 0.0275 - val_mean_absolute_error: 0.1059\n",
                        "\n",
                        "Epoch 00020: val_loss improved from 0.02971 to 0.02750, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 19 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_21/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0275.\n",
                        "Epoch 21/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0133 - mean_absolute_error: 0.0805 - val_loss: 0.0304 - val_mean_absolute_error: 0.1118\n",
                        "\n",
                        "Epoch 00021: val_loss did not improve from 0.02750\n",
                        "No alternative save happened on for epoch 20\n",
                        "Epoch 22/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0131 - mean_absolute_error: 0.0796 - val_loss: 0.0283 - val_mean_absolute_error: 0.1112\n",
                        "\n",
                        "Epoch 00022: val_loss did not improve from 0.02750\n",
                        "No alternative save happened on for epoch 21\n",
                        "Epoch 23/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0131 - mean_absolute_error: 0.0799 - val_loss: 0.0305 - val_mean_absolute_error: 0.1142\n",
                        "\n",
                        "Epoch 00023: val_loss did not improve from 0.02750\n",
                        "No alternative save happened on for epoch 22\n",
                        "Epoch 24/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0129 - mean_absolute_error: 0.0790 - val_loss: 0.0306 - val_mean_absolute_error: 0.1148\n",
                        "\n",
                        "Epoch 00024: val_loss did not improve from 0.02750\n",
                        "No alternative save happened on for epoch 23\n",
                        "Epoch 25/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0130 - mean_absolute_error: 0.0796 - val_loss: 0.0314 - val_mean_absolute_error: 0.1163\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Epoch 00025: val_loss did not improve from 0.02750\n",
                        "No alternative save happened on for epoch 24\n",
                        "Starting kpi calculation...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 1/1 [00:24<00:00, 24.15s/it]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "5\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='flatten_2/Reshape:0', description=\"created by layer 'flatten_2'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
                        "Epoch 1/100\n",
                        "1445/1445 [==============================] - 18s 10ms/step - loss: 0.0642 - mean_absolute_error: 0.1680 - val_loss: 0.0466 - val_mean_absolute_error: 0.1505\n",
                        "\n",
                        "Epoch 00001: val_loss improved from inf to 0.04665, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 0 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0466.\n",
                        "Epoch 2/100\n",
                        "1445/1445 [==============================] - 16s 10ms/step - loss: 0.0220 - mean_absolute_error: 0.1059 - val_loss: 0.0419 - val_mean_absolute_error: 0.1384\n",
                        "\n",
                        "Epoch 00002: val_loss improved from 0.04665 to 0.04187, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 1 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0419.\n",
                        "Epoch 3/100\n",
                        "1445/1445 [==============================] - 15s 11ms/step - loss: 0.0193 - mean_absolute_error: 0.0991 - val_loss: 0.0351 - val_mean_absolute_error: 0.1182\n",
                        "\n",
                        "Epoch 00003: val_loss improved from 0.04187 to 0.03513, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 2 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0351.\n",
                        "Epoch 4/100\n",
                        "1445/1445 [==============================] - 20s 13ms/step - loss: 0.0187 - mean_absolute_error: 0.0972 - val_loss: 0.0364 - val_mean_absolute_error: 0.1255\n",
                        "\n",
                        "Epoch 00004: val_loss did not improve from 0.03513\n",
                        "No alternative save happened on for epoch 3\n",
                        "Epoch 5/100\n",
                        "1445/1445 [==============================] - 16s 11ms/step - loss: 0.0183 - mean_absolute_error: 0.0963 - val_loss: 0.0368 - val_mean_absolute_error: 0.1288\n",
                        "\n",
                        "Epoch 00005: val_loss did not improve from 0.03513\n",
                        "No alternative save happened on for epoch 4\n",
                        "Epoch 6/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0177 - mean_absolute_error: 0.0940 - val_loss: 0.0374 - val_mean_absolute_error: 0.1300\n",
                        "\n",
                        "Epoch 00006: val_loss did not improve from 0.03513\n",
                        "No alternative save happened on for epoch 5\n",
                        "Epoch 7/100\n",
                        "1445/1445 [==============================] - 17s 11ms/step - loss: 0.0171 - mean_absolute_error: 0.0924 - val_loss: 0.0353 - val_mean_absolute_error: 0.1254\n",
                        "\n",
                        "Epoch 00007: val_loss did not improve from 0.03513\n",
                        "No alternative save happened on for epoch 6\n",
                        "Epoch 8/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0164 - mean_absolute_error: 0.0907 - val_loss: 0.0344 - val_mean_absolute_error: 0.1206\n",
                        "\n",
                        "Epoch 00008: val_loss improved from 0.03513 to 0.03443, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 7 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0344.\n",
                        "Epoch 9/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0169 - mean_absolute_error: 0.0922 - val_loss: 0.0350 - val_mean_absolute_error: 0.1260\n",
                        "\n",
                        "Epoch 00009: val_loss did not improve from 0.03443\n",
                        "No alternative save happened on for epoch 8\n",
                        "Epoch 10/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0157 - mean_absolute_error: 0.0881 - val_loss: 0.0344 - val_mean_absolute_error: 0.1208\n",
                        "\n",
                        "Epoch 00010: val_loss improved from 0.03443 to 0.03439, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 9 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0344.\n",
                        "Epoch 11/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0159 - mean_absolute_error: 0.0883 - val_loss: 0.0322 - val_mean_absolute_error: 0.1178\n",
                        "\n",
                        "Epoch 00011: val_loss improved from 0.03439 to 0.03222, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 10 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0322.\n",
                        "Epoch 12/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0151 - mean_absolute_error: 0.0858 - val_loss: 0.0323 - val_mean_absolute_error: 0.1172\n",
                        "\n",
                        "Epoch 00012: val_loss did not improve from 0.03222\n",
                        "No alternative save happened on for epoch 11\n",
                        "Epoch 13/100\n",
                        "1445/1445 [==============================] - 42s 29ms/step - loss: 0.0149 - mean_absolute_error: 0.0856 - val_loss: 0.0300 - val_mean_absolute_error: 0.1114\n",
                        "\n",
                        "Epoch 00013: val_loss improved from 0.03222 to 0.03001, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 12 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0300.\n",
                        "Epoch 14/100\n",
                        "1445/1445 [==============================] - 25s 17ms/step - loss: 0.0148 - mean_absolute_error: 0.0855 - val_loss: 0.0297 - val_mean_absolute_error: 0.1093\n",
                        "\n",
                        "Epoch 00014: val_loss improved from 0.03001 to 0.02974, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 13 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0297.\n",
                        "Epoch 15/100\n",
                        "1445/1445 [==============================] - 20s 14ms/step - loss: 0.0143 - mean_absolute_error: 0.0838 - val_loss: 0.0327 - val_mean_absolute_error: 0.1180\n",
                        "\n",
                        "Epoch 00015: val_loss did not improve from 0.02974\n",
                        "No alternative save happened on for epoch 14\n",
                        "Epoch 16/100\n",
                        "1445/1445 [==============================] - 27s 19ms/step - loss: 0.0143 - mean_absolute_error: 0.0842 - val_loss: 0.0315 - val_mean_absolute_error: 0.1139\n",
                        "\n",
                        "Epoch 00016: val_loss did not improve from 0.02974\n",
                        "No alternative save happened on for epoch 15\n",
                        "Epoch 17/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0139 - mean_absolute_error: 0.0821 - val_loss: 0.0295 - val_mean_absolute_error: 0.1104\n",
                        "\n",
                        "Epoch 00017: val_loss improved from 0.02974 to 0.02952, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 16 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0295.\n",
                        "Epoch 18/100\n",
                        "1445/1445 [==============================] - 22s 15ms/step - loss: 0.0137 - mean_absolute_error: 0.0818 - val_loss: 0.0274 - val_mean_absolute_error: 0.1035\n",
                        "\n",
                        "Epoch 00018: val_loss improved from 0.02952 to 0.02742, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 17 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_31/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0274.\n",
                        "Epoch 19/100\n",
                        "1445/1445 [==============================] - 30s 21ms/step - loss: 0.0137 - mean_absolute_error: 0.0817 - val_loss: 0.0308 - val_mean_absolute_error: 0.1183\n",
                        "\n",
                        "Epoch 00019: val_loss did not improve from 0.02742\n",
                        "No alternative save happened on for epoch 18\n",
                        "Epoch 20/100\n",
                        "1445/1445 [==============================] - 32s 22ms/step - loss: 0.0135 - mean_absolute_error: 0.0811 - val_loss: 0.0313 - val_mean_absolute_error: 0.1126\n",
                        "\n",
                        "Epoch 00020: val_loss did not improve from 0.02742\n",
                        "No alternative save happened on for epoch 19\n",
                        "Epoch 21/100\n",
                        "1445/1445 [==============================] - 28s 19ms/step - loss: 0.0132 - mean_absolute_error: 0.0800 - val_loss: 0.0280 - val_mean_absolute_error: 0.1060\n",
                        "\n",
                        "Epoch 00021: val_loss did not improve from 0.02742\n",
                        "No alternative save happened on for epoch 20\n",
                        "Epoch 22/100\n",
                        "1445/1445 [==============================] - 29s 20ms/step - loss: 0.0132 - mean_absolute_error: 0.0804 - val_loss: 0.0327 - val_mean_absolute_error: 0.1204\n",
                        "\n",
                        "Epoch 00022: val_loss did not improve from 0.02742\n",
                        "No alternative save happened on for epoch 21\n",
                        "Epoch 23/100\n",
                        "1445/1445 [==============================] - 29s 20ms/step - loss: 0.0131 - mean_absolute_error: 0.0796 - val_loss: 0.0274 - val_mean_absolute_error: 0.1035\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Epoch 00023: val_loss did not improve from 0.02742\n",
                        "No alternative save happened on for epoch 22\n",
                        "Starting kpi calculation...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 1/1 [00:35<00:00, 35.03s/it]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "5\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='flatten_4/Reshape:0', description=\"created by layer 'flatten_4'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
                        "Epoch 1/100\n",
                        "1445/1445 [==============================] - 28s 16ms/step - loss: 0.0653 - mean_absolute_error: 0.1644 - val_loss: 0.0742 - val_mean_absolute_error: 0.2007\n",
                        "\n",
                        "Epoch 00001: val_loss improved from inf to 0.07422, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 0 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0742.\n",
                        "Epoch 2/100\n",
                        "1445/1445 [==============================] - 26s 18ms/step - loss: 0.0235 - mean_absolute_error: 0.1094 - val_loss: 0.0372 - val_mean_absolute_error: 0.1287\n",
                        "\n",
                        "Epoch 00002: val_loss improved from 0.07422 to 0.03716, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 1 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0372.\n",
                        "Epoch 3/100\n",
                        "1445/1445 [==============================] - 24s 16ms/step - loss: 0.0199 - mean_absolute_error: 0.1006 - val_loss: 0.0353 - val_mean_absolute_error: 0.1202\n",
                        "\n",
                        "Epoch 00003: val_loss improved from 0.03716 to 0.03532, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 2 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0353.\n",
                        "Epoch 4/100\n",
                        "1445/1445 [==============================] - 23s 16ms/step - loss: 0.0188 - mean_absolute_error: 0.0975 - val_loss: 0.0350 - val_mean_absolute_error: 0.1231\n",
                        "\n",
                        "Epoch 00004: val_loss improved from 0.03532 to 0.03500, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 3 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0350.\n",
                        "Epoch 5/100\n",
                        "1445/1445 [==============================] - 23s 15ms/step - loss: 0.0181 - mean_absolute_error: 0.0958 - val_loss: 0.0409 - val_mean_absolute_error: 0.1378\n",
                        "\n",
                        "Epoch 00005: val_loss did not improve from 0.03500\n",
                        "No alternative save happened on for epoch 4\n",
                        "Epoch 6/100\n",
                        "1445/1445 [==============================] - 24s 16ms/step - loss: 0.0176 - mean_absolute_error: 0.0942 - val_loss: 0.0320 - val_mean_absolute_error: 0.1190\n",
                        "\n",
                        "Epoch 00006: val_loss improved from 0.03500 to 0.03200, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 5 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0320.\n",
                        "Epoch 7/100\n",
                        "1445/1445 [==============================] - 27s 19ms/step - loss: 0.0165 - mean_absolute_error: 0.0908 - val_loss: 0.0320 - val_mean_absolute_error: 0.1153\n",
                        "\n",
                        "Epoch 00007: val_loss improved from 0.03200 to 0.03199, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 6 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0320.\n",
                        "Epoch 8/100\n",
                        "1445/1445 [==============================] - 29s 20ms/step - loss: 0.0165 - mean_absolute_error: 0.0907 - val_loss: 0.0303 - val_mean_absolute_error: 0.1099\n",
                        "\n",
                        "Epoch 00008: val_loss improved from 0.03199 to 0.03029, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 7 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_42/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0303.\n",
                        "Epoch 9/100\n",
                        "1445/1445 [==============================] - 24s 16ms/step - loss: 0.0161 - mean_absolute_error: 0.0897 - val_loss: 0.0336 - val_mean_absolute_error: 0.1202\n",
                        "\n",
                        "Epoch 00009: val_loss did not improve from 0.03029\n",
                        "No alternative save happened on for epoch 8\n",
                        "Epoch 10/100\n",
                        "1445/1445 [==============================] - 26s 18ms/step - loss: 0.0156 - mean_absolute_error: 0.0884 - val_loss: 0.0304 - val_mean_absolute_error: 0.1120\n",
                        "\n",
                        "Epoch 00010: val_loss did not improve from 0.03029\n",
                        "No alternative save happened on for epoch 9\n",
                        "Epoch 11/100\n",
                        "1445/1445 [==============================] - 27s 19ms/step - loss: 0.0154 - mean_absolute_error: 0.0875 - val_loss: 0.0351 - val_mean_absolute_error: 0.1228\n",
                        "\n",
                        "Epoch 00011: val_loss did not improve from 0.03029\n",
                        "No alternative save happened on for epoch 10\n",
                        "Epoch 12/100\n",
                        "1445/1445 [==============================] - 27s 19ms/step - loss: 0.0150 - mean_absolute_error: 0.0864 - val_loss: 0.0315 - val_mean_absolute_error: 0.1155\n",
                        "\n",
                        "Epoch 00012: val_loss did not improve from 0.03029\n",
                        "No alternative save happened on for epoch 11\n",
                        "Epoch 13/100\n",
                        "1445/1445 [==============================] - 29s 20ms/step - loss: 0.0148 - mean_absolute_error: 0.0854 - val_loss: 0.0319 - val_mean_absolute_error: 0.1159\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Epoch 00013: val_loss did not improve from 0.03029\n",
                        "No alternative save happened on for epoch 12\n",
                        "Starting kpi calculation...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 1/1 [00:42<00:00, 42.72s/it]\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "5\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 5, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 64), dtype=tf.float32, name=None), name='flatten_6/Reshape:0', description=\"created by layer 'flatten_6'\")\n",
                        "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
                        "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
                        "Epoch 1/100\n",
                        "1445/1445 [==============================] - 28s 15ms/step - loss: 0.0676 - mean_absolute_error: 0.1705 - val_loss: 0.0621 - val_mean_absolute_error: 0.1737\n",
                        "\n",
                        "Epoch 00001: val_loss improved from inf to 0.06209, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 0 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0621.\n",
                        "Epoch 2/100\n",
                        "1445/1445 [==============================] - 23s 16ms/step - loss: 0.0230 - mean_absolute_error: 0.1083 - val_loss: 0.0378 - val_mean_absolute_error: 0.1317\n",
                        "\n",
                        "Epoch 00002: val_loss improved from 0.06209 to 0.03781, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 1 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0378.\n",
                        "Epoch 3/100\n",
                        "1445/1445 [==============================] - 23s 16ms/step - loss: 0.0201 - mean_absolute_error: 0.1015 - val_loss: 0.0413 - val_mean_absolute_error: 0.1374\n",
                        "\n",
                        "Epoch 00003: val_loss did not improve from 0.03781\n",
                        "No alternative save happened on for epoch 2\n",
                        "Epoch 4/100\n",
                        "1445/1445 [==============================] - 29s 19ms/step - loss: 0.0193 - mean_absolute_error: 0.0990 - val_loss: 0.0353 - val_mean_absolute_error: 0.1202\n",
                        "\n",
                        "Epoch 00004: val_loss improved from 0.03781 to 0.03534, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 3 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0353.\n",
                        "Epoch 5/100\n",
                        "1445/1445 [==============================] - 25s 17ms/step - loss: 0.0182 - mean_absolute_error: 0.0956 - val_loss: 0.0334 - val_mean_absolute_error: 0.1199\n",
                        "\n",
                        "Epoch 00005: val_loss improved from 0.03534 to 0.03337, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 4 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0334.\n",
                        "Epoch 6/100\n",
                        "1445/1445 [==============================] - 17s 12ms/step - loss: 0.0181 - mean_absolute_error: 0.0953 - val_loss: 0.0311 - val_mean_absolute_error: 0.1145\n",
                        "\n",
                        "Epoch 00006: val_loss improved from 0.03337 to 0.03112, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 5 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0311.\n",
                        "Epoch 7/100\n",
                        "1445/1445 [==============================] - 24s 16ms/step - loss: 0.0174 - mean_absolute_error: 0.0934 - val_loss: 0.0331 - val_mean_absolute_error: 0.1185\n",
                        "\n",
                        "Epoch 00007: val_loss did not improve from 0.03112\n",
                        "No alternative save happened on for epoch 6\n",
                        "Epoch 8/100\n",
                        "1445/1445 [==============================] - 18s 12ms/step - loss: 0.0168 - mean_absolute_error: 0.0918 - val_loss: 0.0332 - val_mean_absolute_error: 0.1179\n",
                        "\n",
                        "Epoch 00008: val_loss did not improve from 0.03112\n",
                        "No alternative save happened on for epoch 7\n",
                        "Epoch 9/100\n",
                        "1445/1445 [==============================] - 22s 15ms/step - loss: 0.0162 - mean_absolute_error: 0.0895 - val_loss: 0.0318 - val_mean_absolute_error: 0.1184\n",
                        "\n",
                        "Epoch 00009: val_loss did not improve from 0.03112\n",
                        "No alternative save happened on for epoch 8\n",
                        "Epoch 10/100\n",
                        "1445/1445 [==============================] - 23s 16ms/step - loss: 0.0162 - mean_absolute_error: 0.0899 - val_loss: 0.0297 - val_mean_absolute_error: 0.1119\n",
                        "\n",
                        "Epoch 00010: val_loss improved from 0.03112 to 0.02970, saving model to data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle\n",
                        "Alternative save happened on for epoch 9 happened on data/model_weights/checkpoints/cp_path_pred_kpi/20_07_2021__09_50/destTrueconnpFalseallpFalse.pickle for val_loss of 0.0297.\n",
                        "Epoch 11/100\n",
                        "1445/1445 [==============================] - 22s 15ms/step - loss: 0.0157 - mean_absolute_error: 0.0884 - val_loss: 0.0330 - val_mean_absolute_error: 0.1158\n",
                        "\n",
                        "Epoch 00011: val_loss did not improve from 0.02970\n",
                        "No alternative save happened on for epoch 10\n",
                        "Epoch 12/100\n",
                        "1445/1445 [==============================] - 21s 14ms/step - loss: 0.0152 - mean_absolute_error: 0.0867 - val_loss: 0.0363 - val_mean_absolute_error: 0.1256\n",
                        "\n",
                        "Epoch 00012: val_loss did not improve from 0.02970\n",
                        "No alternative save happened on for epoch 11\n",
                        "Epoch 13/100\n",
                        "1445/1445 [==============================] - 21s 14ms/step - loss: 0.0149 - mean_absolute_error: 0.0858 - val_loss: 0.0324 - val_mean_absolute_error: 0.1176\n",
                        "\n",
                        "Epoch 00013: val_loss did not improve from 0.02970\n",
                        "No alternative save happened on for epoch 12\n",
                        "Epoch 14/100\n",
                        "1445/1445 [==============================] - 25s 17ms/step - loss: 0.0147 - mean_absolute_error: 0.0848 - val_loss: 0.0312 - val_mean_absolute_error: 0.1121\n",
                        "\n",
                        "Epoch 00014: val_loss did not improve from 0.02970\n",
                        "No alternative save happened on for epoch 13\n",
                        "Epoch 15/100\n",
                        "1445/1445 [==============================] - 19s 13ms/step - loss: 0.0142 - mean_absolute_error: 0.0831 - val_loss: 0.0332 - val_mean_absolute_error: 0.1232\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "  0%|          | 0/1 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "\n",
                        "Epoch 00015: val_loss did not improve from 0.02970\n",
                        "No alternative save happened on for epoch 14\n",
                        "Starting kpi calculation...\n"
                    ]
                },
                {
                    "output_type": "stream",
                    "name": "stderr",
                    "text": [
                        "100%|██████████| 1/1 [00:25<00:00, 25.34s/it]\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "source": [
                "def calc_distances(a):\n",
                "    return np.sqrt(np.square(a[0]-a[2])+np.square(a[1]-a[3]))\n",
                "\n",
                "lala = np.array([[1., 0.], [2.,1.]])\n",
                "lala = np.hstack([lala, lala+1])\n",
                "\n",
                "np.apply_along_axis(f, 1, lala)\n"
            ],
            "outputs": [
                {
                    "output_type": "execute_result",
                    "data": {
                        "text/plain": [
                            "array([1.41421356, 1.41421356])"
                        ]
                    },
                    "metadata": {},
                    "execution_count": 22
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.8.5",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.8.5 64-bit ('thesis_basic': conda)"
        },
        "interpreter": {
            "hash": "670cfe7939475ebb968c924b13a14a1c26d345d90444bab171f80d257de98d85"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}