{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __return_waypoints_ind():\n",
    "    d = np.array([\n",
    "    [ 65, -36],\n",
    "    [ 56, -21],\n",
    "    [ 66, -46],\n",
    "    [ 58, -48],\n",
    "    [ 67, -29],\n",
    "    [ 61, -16],\n",
    "    [ 45, -32],\n",
    "    [ 71, -43],\n",
    "    # [ 80, -52],\n",
    "    # [ 68, -58],\n",
    "    [ 65, -54],\n",
    "    [ 48, -20],\n",
    "    [ 64, -21],\n",
    "    [ 46, -14]])\n",
    "    return d\n",
    "\n",
    "\n",
    "def __return_waypoints_sdd():\n",
    "    d = np.array([[24, 34],\n",
    "       [16, 35],\n",
    "       [24, 20],\n",
    "       [14, 20],\n",
    "       [14, 11],\n",
    "       [ 6, 33],\n",
    "       [ 7, 47],\n",
    "       [23, 48]])\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'dataset' at 0x7f3b657dde00>\n",
      "<Element 'dataset' at 0x7f3b657e84f0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(array(['w0', 'd6', 'w7'], dtype='<U2'),\n",
       "  [(24, 34), (25.12452065, 45.36610442), (23, 48)]),\n",
       " ([], []),\n",
       " ([], []),\n",
       " (array(['d0', 'w5', 'w1', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (16, 35),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443)]),\n",
       " (array(['d3', 'd4', 'w2', 'w0'], dtype='<U2'),\n",
       "  [(18.44346834, 0.86828017), (23.60483923, 0.91962773), (24, 20), (24, 34)]),\n",
       " (array(['d7', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(0.29354899, 22.89682134), (14, 20), (14, 11), (18.44346834, 0.86828017)]),\n",
       " (array(['d1', 'w0', 'd6', 'w7'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443), (24, 34), (25.12452065, 45.36610442), (23, 48)]),\n",
       " (array(['w0', 'w2'], dtype='<U2'), [(24, 34), (24, 20)]),\n",
       " (array(['d4', 'w2', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773), (24, 20), (24, 34), (37.4084038, 33.74739443)]),\n",
       " (array(['d2', 'w7', 'd6', 'w0', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34),\n",
       "   (24, 20),\n",
       "   (23.60483923, 0.91962773)]),\n",
       " (array(['w7', 'd2'], dtype='<U2'), [(23, 48), (25.14758057, 53.29443775)]),\n",
       " (array(['d4', 'w2', 'w0', 'd6', 'w7', 'd2'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775)]),\n",
       " (array(['d8'], dtype='<U2'), [(39.78424137, 24.5101475)]),\n",
       " (array(['d6', 'w7', 'd5'], dtype='<U2'),\n",
       "  [(25.12452065, 45.36610442), (23, 48), (9.62586124, 54.87695537)]),\n",
       " (array(['d1'], dtype='<U2'), [(37.4084038, 33.74739443)]),\n",
       " (array(['w0', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(24, 34), (24, 20), (23.60483923, 0.91962773)]),\n",
       " (array(['w0', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(24, 34), (24, 20), (23.60483923, 0.91962773)]),\n",
       " (array(['d3', 'w4', 'd7'], dtype='<U2'),\n",
       "  [(18.44346834, 0.86828017), (14, 11), (0.29354899, 22.89682134)]),\n",
       " ([], []),\n",
       " (array(['d2', 'w7', 'd6', 'w0', 'w2', 'd4', 'd3'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34),\n",
       "   (24, 20),\n",
       "   (23.60483923, 0.91962773),\n",
       "   (18.44346834, 0.86828017)]),\n",
       " (array(['d4'], dtype='<U2'), [(23.60483923, 0.91962773)]),\n",
       " (array(['d4'], dtype='<U2'), [(23.60483923, 0.91962773)]),\n",
       " (array(['d7', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(0.29354899, 22.89682134), (14, 11), (18.44346834, 0.86828017)]),\n",
       " (array(['d4', 'w2', 'w0', 'd6', 'w7', 'd2'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775)]),\n",
       " (array(['d4', 'w2', 'w0', 'd6', 'w7', 'd2', 'w7', 'd6', 'w0', 'd1'],\n",
       "        dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443)]),\n",
       " (array(['d8', 'd1', 'w0', 'd6', 'w7', 'd2', 'w7', 'd6'], dtype='<U2'),\n",
       "  [(39.78424137, 24.5101475),\n",
       "   (37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442)]),\n",
       " (array(['d2'], dtype='<U2'), [(25.14758057, 53.29443775)]),\n",
       " (array(['w1', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(16, 35), (24, 34), (37.4084038, 33.74739443)]),\n",
       " (array(['d5', 'w6', 'd0'], dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537), (7, 47), (0.80188993, 33.06466289)]),\n",
       " (array(['d4', 'd3', 'w4', 'w3', 'd7', 'w4', 'd3', 'd4'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (18.44346834, 0.86828017),\n",
       "   (14, 11),\n",
       "   (14, 20),\n",
       "   (0.29354899, 22.89682134),\n",
       "   (14, 11),\n",
       "   (18.44346834, 0.86828017),\n",
       "   (23.60483923, 0.91962773)]),\n",
       " (array(['w1', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(16, 35), (14, 20), (14, 11), (18.44346834, 0.86828017)]),\n",
       " (array(['d4', 'w2', 'w0', 'w1', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (14, 20),\n",
       "   (14, 11),\n",
       "   (18.44346834, 0.86828017)]),\n",
       " (array(['d2'], dtype='<U2'), [(25.14758057, 53.29443775)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443), (24, 34), (16, 35), (6, 33)]),\n",
       " (array(['d4', 'w2', 'w0', 'd6', 'w7', 'd5'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (9.62586124, 54.87695537)]),\n",
       " (array(['d3', 'w4', 'w3'], dtype='<U2'),\n",
       "  [(18.44346834, 0.86828017), (14, 11), (14, 20)]),\n",
       " (array(['d2', 'w7', 'd6', 'w0'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34)]),\n",
       " (array(['d2', 'w7', 'd6', 'w0'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34)]),\n",
       " ([], []),\n",
       " (array(['w1', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(16, 35), (14, 20), (14, 11), (18.44346834, 0.86828017)]),\n",
       " (array(['d5', 'w6'], dtype='<U2'), [(9.62586124, 54.87695537), (7, 47)]),\n",
       " (array(['d8', 'w2', 'w3', 'd7'], dtype='<U2'),\n",
       "  [(39.78424137, 24.5101475), (24, 20), (14, 20), (0.29354899, 22.89682134)]),\n",
       " (array(['d2', 'w7'], dtype='<U2'), [(25.14758057, 53.29443775), (23, 48)]),\n",
       " (array(['d8', 'w2', 'w4'], dtype='<U2'),\n",
       "  [(39.78424137, 24.5101475), (24, 20), (14, 11)]),\n",
       " (array(['d1', 'w0', 'd6', 'w7', 'd2'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775)]),\n",
       " (array(['d2', 'w7', 'd6'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775), (23, 48), (25.12452065, 45.36610442)]),\n",
       " (array(['d2', 'w7', 'd6'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775), (23, 48), (25.12452065, 45.36610442)]),\n",
       " (array(['w1', 'w3', 'w4', 'd4'], dtype='<U2'),\n",
       "  [(16, 35), (14, 20), (14, 11), (23.60483923, 0.91962773)]),\n",
       " (array(['d2', 'd5', 'w6', 'd0'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (9.62586124, 54.87695537),\n",
       "   (7, 47),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d0', 'w5', 'w1', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (16, 35),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443)]),\n",
       " (array(['d4', 'w2', 'w1', 'd5'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773), (24, 20), (16, 35), (9.62586124, 54.87695537)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d0', 'w6', 'd5'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289), (7, 47), (9.62586124, 54.87695537)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd7'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.29354899, 22.89682134)]),\n",
       " (array(['d5', 'w6', 'w5', 'd0', 'd7'], dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537),\n",
       "   (7, 47),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289),\n",
       "   (0.29354899, 22.89682134)]),\n",
       " (array(['d3', 'w1'], dtype='<U2'), [(18.44346834, 0.86828017), (16, 35)]),\n",
       " (array(['d1', 'w0', 'w1', 'w6', 'd5'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (7, 47),\n",
       "   (9.62586124, 54.87695537)]),\n",
       " (array(['w4', 'w3', 'w5', 'w6', 'd5'], dtype='<U2'),\n",
       "  [(14, 11), (14, 20), (6, 33), (7, 47), (9.62586124, 54.87695537)]),\n",
       " (array(['d5', 'w6', 'd0'], dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537), (7, 47), (0.80188993, 33.06466289)]),\n",
       " (array(['w7', 'd6', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(23, 48), (25.12452065, 45.36610442), (24, 34), (37.4084038, 33.74739443)]),\n",
       " (array(['d4', 'w2', 'd1'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773), (24, 20), (37.4084038, 33.74739443)]),\n",
       " (array(['d2', 'w7', 'd6'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775), (23, 48), (25.12452065, 45.36610442)]),\n",
       " ([], []),\n",
       " ([], []),\n",
       " (array(['d4', 'w2', 'd1'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773), (24, 20), (37.4084038, 33.74739443)]),\n",
       " (array(['d5'], dtype='<U2'), [(9.62586124, 54.87695537)]),\n",
       " (array(['d0', 'w5', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (14, 20),\n",
       "   (14, 11),\n",
       "   (18.44346834, 0.86828017)]),\n",
       " (array(['w7', 'd2'], dtype='<U2'), [(23, 48), (25.14758057, 53.29443775)]),\n",
       " (array(['w7'], dtype='<U2'), [(23, 48)]),\n",
       " (array(['d3', 'w4', 'w3', 'w1', 'w6', 'd5'], dtype='<U2'),\n",
       "  [(18.44346834, 0.86828017),\n",
       "   (14, 11),\n",
       "   (14, 20),\n",
       "   (16, 35),\n",
       "   (7, 47),\n",
       "   (9.62586124, 54.87695537)]),\n",
       " (array(['d5', 'w6', 'w1', 'w3', 'w4', 'd3', 'w4', 'w3', 'w6', 'd5'],\n",
       "        dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537),\n",
       "   (7, 47),\n",
       "   (16, 35),\n",
       "   (14, 20),\n",
       "   (14, 11),\n",
       "   (18.44346834, 0.86828017),\n",
       "   (14, 11),\n",
       "   (14, 20),\n",
       "   (7, 47),\n",
       "   (9.62586124, 54.87695537)]),\n",
       " (array(['d2', 'w7', 'd6', 'w0', 'w2', 'd4', 'w2', 'd8'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34),\n",
       "   (24, 20),\n",
       "   (23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (39.78424137, 24.5101475)]),\n",
       " (array(['d5', 'w3', 'w4', 'd3'], dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537), (14, 20), (14, 11), (18.44346834, 0.86828017)]),\n",
       " (array(['d2', 'w7', 'd6', 'w0', 'd1'], dtype='<U2'),\n",
       "  [(25.14758057, 53.29443775),\n",
       "   (23, 48),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443)]),\n",
       " (array(['d8', 'w2', 'w3', 'd7'], dtype='<U2'),\n",
       "  [(39.78424137, 24.5101475), (24, 20), (14, 20), (0.29354899, 22.89682134)]),\n",
       " (array(['w1', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(16, 35), (24, 20), (23.60483923, 0.91962773)]),\n",
       " (array(['w6'], dtype='<U2'), [(7, 47)]),\n",
       " (array(['d5', 'w0', 'd1', 'w0', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(9.62586124, 54.87695537),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d0', 'w5', 'w1', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (16, 35),\n",
       "   (24, 20),\n",
       "   (23.60483923, 0.91962773)]),\n",
       " (array(['d0', 'w5', 'w1', 'w2', 'd4'], dtype='<U2'),\n",
       "  [(0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (16, 35),\n",
       "   (24, 20),\n",
       "   (23.60483923, 0.91962773)]),\n",
       " (array(['w0', 'd8'], dtype='<U2'), [(24, 34), (39.78424137, 24.5101475)]),\n",
       " (array(['d1', 'w0', 'd6', 'w7', 'd2'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775)]),\n",
       " (array(['d4', 'w2', 'w0', 'd6', 'w7', 'd2'], dtype='<U2'),\n",
       "  [(23.60483923, 0.91962773),\n",
       "   (24, 20),\n",
       "   (24, 34),\n",
       "   (25.12452065, 45.36610442),\n",
       "   (23, 48),\n",
       "   (25.14758057, 53.29443775)]),\n",
       " (array(['d3', 'w4', 'w3', 'w1'], dtype='<U2'),\n",
       "  [(18.44346834, 0.86828017), (14, 11), (14, 20), (16, 35)]),\n",
       " (array(['d1', 'w0', 'w1', 'w5', 'd0', 'w5', 'w1', 'w0', 'd1', 'w0', 'w1',\n",
       "         'w5', 'd0'], dtype='<U2'),\n",
       "  [(37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289),\n",
       "   (6, 33),\n",
       "   (16, 35),\n",
       "   (24, 34),\n",
       "   (37.4084038, 33.74739443),\n",
       "   (24, 34),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d8', 'w2', 'w1', 'w5', 'd0'], dtype='<U2'),\n",
       "  [(39.78424137, 24.5101475),\n",
       "   (24, 20),\n",
       "   (16, 35),\n",
       "   (6, 33),\n",
       "   (0.80188993, 33.06466289)]),\n",
       " (array(['d1'], dtype='<U2'), [(37.4084038, 33.74739443)]),\n",
       " (array(['d1'], dtype='<U2'), [(37.4084038, 33.74739443)])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys\n",
    "from helpers.highlevel_sceneloader import HighLevelSceneLoader\n",
    "from predictors.dataset_creator import TFDataSet\n",
    "import tensorflow as tf\n",
    "from predictors.dl_trainer import DLTrainer \n",
    "from predictors.extended_predictor import extended_predictor \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from helpers.graph import Graph\n",
    "from helpers.accuracy_functions import destination_distance_l\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "''' set some parameters '''\n",
    "# Model parameters\n",
    "LSTM_LAYER_SIZE = 32\n",
    "DENSE_LAYER_SIZE = 32\n",
    "NUM_LSTM_LAYERS = 2\n",
    "NUM_DENSE_LAYERS = 2\n",
    "VARIABLE_INPUT_LENGTH = False\n",
    "\n",
    "# Dataset\n",
    "SEQ_IN_LEN = 3\n",
    "SEQ_OUT_LEN = 4\n",
    "NOISE_STD = .1\n",
    "N_REPEATS = 1\n",
    "\n",
    "BATCH_SIZE = 5\n",
    "LENGTH_STRIDE = 2\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "MAX_EPOCHS = 100\n",
    "PATIENCE = 10\n",
    "\n",
    "# For graph\n",
    "GRAPH_DIST_THRESH = 4\n",
    "\n",
    "''' get the data '''\n",
    "ROOT = os.getcwd()\n",
    "\n",
    "rel_p_img_b = 'helpers/analysed_vars_storage/img_bounds.xml'\n",
    "rel_p_dests = 'helpers/analysed_vars_storage/destination_locations.xml'\n",
    "p_img_bounds = os.path.join(ROOT, rel_p_img_b)\n",
    "p_dest_locs = os.path.join(ROOT, rel_p_dests)\n",
    "\n",
    "#TODO: older version of OpenTraj needed: \"git checkout d249ba6951dd0f54b532fbe2ca6edc46b0d7093f\"\n",
    "opentraj_root = os.path.join(ROOT, 'OpenTraj')\n",
    "root_datasets = os.path.join(ROOT, 'data/path_data')\n",
    "sys.path.append(opentraj_root) # add package to pythonpath\n",
    "\n",
    "scene_data = HighLevelSceneLoader(p_img_bounds, p_dest_locs)\n",
    "# scene_data.load_ind(root_datasets, 7, 17)\n",
    "scene_data.load_sdd(opentraj_root, \"little\", \"video3\")\n",
    "\n",
    "\n",
    "''' create the graph instance '''    \n",
    "interest_points = __return_waypoints_sdd()\n",
    "g = Graph.from_matrices(interest_points, scene_data.destination_matrix, GRAPH_DIST_THRESH, .05)\n",
    "\n",
    "df_signals = scene_data.df_to_lst_realxy_mats()\n",
    "g.analyse_multiple_full_signals(df_signals, add_to_trams_mat=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' time to create df datasets '''\n",
    "extra_features_dict = {\n",
    "    \"all_points\": None,\n",
    "    \"all_destinations\": None,\n",
    "    \"n_destinations\": 5,\n",
    "    \"n_points\": 5,\n",
    "    \"n_connected_points_after\" : 3\n",
    "}\n",
    "\n",
    "# # Load data in order to not need to do calculations again\n",
    "with open(\"data/pickle/ds_creation_d/ds_7to17_inputLabels3_4_low_noise.pickle\", 'rb') as handle: #\"data/pickle/ds_creation_d/bs1.pickle\"\n",
    "    my_ds_creation_dict = pickle.load(handle)\n",
    "\n",
    "my_ds = TFDataSet.init_as_fixed_length(scene_data.traj_dataframe, graph=g, var_in_len=VARIABLE_INPUT_LENGTH, length_stride=LENGTH_STRIDE,\n",
    "scale_list=[\"pos_x\", \"pos_y\"], seq_in_length=SEQ_IN_LEN, label_length=SEQ_OUT_LEN,\n",
    "extra_features_dict=extra_features_dict, noise_std=NOISE_STD, \n",
    "n_repeats=N_REPEATS, batch_size=BATCH_SIZE, ds_creation_dict=my_ds_creation_dict) #save_folder = \"data/pickle/ds_creation_d/ds_7to17_inputLabels3_4_low_noise.pickle\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 3, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='flatten_1/Reshape:0', description=\"created by layer 'flatten_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/100\n",
      "1862/1862 [==============================] - 27s 10ms/step - loss: 0.0554 - mean_absolute_error: 0.1536 - val_loss: 0.0471 - val_mean_absolute_error: 0.1605\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04714, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 0 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0471.\n",
      "Epoch 2/100\n",
      "1862/1862 [==============================] - 20s 10ms/step - loss: 0.0212 - mean_absolute_error: 0.1073 - val_loss: 0.0347 - val_mean_absolute_error: 0.1347\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04714 to 0.03472, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 1 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0347.\n",
      "Epoch 3/100\n",
      "1862/1862 [==============================] - 25s 13ms/step - loss: 0.0175 - mean_absolute_error: 0.0968 - val_loss: 0.0302 - val_mean_absolute_error: 0.1234\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03472 to 0.03016, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 2 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0302.\n",
      "Epoch 4/100\n",
      "1862/1862 [==============================] - 14s 7ms/step - loss: 0.0138 - mean_absolute_error: 0.0860 - val_loss: 0.0222 - val_mean_absolute_error: 0.1023\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03016 to 0.02224, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 3 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0222.\n",
      "Epoch 5/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0121 - mean_absolute_error: 0.0805 - val_loss: 0.0195 - val_mean_absolute_error: 0.0949\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02224 to 0.01946, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 4 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0195.\n",
      "Epoch 6/100\n",
      "1862/1862 [==============================] - 14s 7ms/step - loss: 0.0116 - mean_absolute_error: 0.0786 - val_loss: 0.0180 - val_mean_absolute_error: 0.0894\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01946 to 0.01797, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 5 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0180.\n",
      "Epoch 7/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0113 - mean_absolute_error: 0.0780 - val_loss: 0.0173 - val_mean_absolute_error: 0.0885\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.01797 to 0.01731, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 6 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0173.\n",
      "Epoch 8/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0110 - mean_absolute_error: 0.0762 - val_loss: 0.0182 - val_mean_absolute_error: 0.0869\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01731\n",
      "No alternative save happened on for epoch 7\n",
      "Epoch 9/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0108 - mean_absolute_error: 0.0758 - val_loss: 0.0214 - val_mean_absolute_error: 0.1000\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01731\n",
      "No alternative save happened on for epoch 8\n",
      "Epoch 10/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0107 - mean_absolute_error: 0.0754 - val_loss: 0.0199 - val_mean_absolute_error: 0.0966\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01731\n",
      "No alternative save happened on for epoch 9\n",
      "Epoch 11/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0739 - val_loss: 0.0177 - val_mean_absolute_error: 0.0866\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01731\n",
      "No alternative save happened on for epoch 10\n",
      "Epoch 12/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0103 - mean_absolute_error: 0.0738 - val_loss: 0.0172 - val_mean_absolute_error: 0.0869\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01731 to 0.01717, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 11 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0172.\n",
      "Epoch 13/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0731 - val_loss: 0.0181 - val_mean_absolute_error: 0.0898\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01717\n",
      "No alternative save happened on for epoch 12\n",
      "Epoch 14/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0101 - mean_absolute_error: 0.0727 - val_loss: 0.0164 - val_mean_absolute_error: 0.0826\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01717 to 0.01638, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 13 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0164.\n",
      "Epoch 15/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0100 - mean_absolute_error: 0.0727 - val_loss: 0.0183 - val_mean_absolute_error: 0.0899\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01638\n",
      "No alternative save happened on for epoch 14\n",
      "Epoch 16/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0097 - mean_absolute_error: 0.0712 - val_loss: 0.0160 - val_mean_absolute_error: 0.0823\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01638 to 0.01604, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 15 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0160.\n",
      "Epoch 17/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0096 - mean_absolute_error: 0.0708 - val_loss: 0.0167 - val_mean_absolute_error: 0.0873\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01604\n",
      "No alternative save happened on for epoch 16\n",
      "Epoch 18/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0096 - mean_absolute_error: 0.0708 - val_loss: 0.0159 - val_mean_absolute_error: 0.0820\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01604 to 0.01586, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 17 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0159.\n",
      "Epoch 19/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0093 - mean_absolute_error: 0.0700 - val_loss: 0.0159 - val_mean_absolute_error: 0.0806\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01586\n",
      "No alternative save happened on for epoch 18\n",
      "Epoch 20/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0096 - mean_absolute_error: 0.0707 - val_loss: 0.0162 - val_mean_absolute_error: 0.0837\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01586\n",
      "No alternative save happened on for epoch 19\n",
      "Epoch 21/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0093 - mean_absolute_error: 0.0697 - val_loss: 0.0157 - val_mean_absolute_error: 0.0813\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01586 to 0.01572, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 20 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0157.\n",
      "Epoch 22/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0092 - mean_absolute_error: 0.0693 - val_loss: 0.0164 - val_mean_absolute_error: 0.0834\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01572\n",
      "No alternative save happened on for epoch 21\n",
      "Epoch 23/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0092 - mean_absolute_error: 0.0689 - val_loss: 0.0177 - val_mean_absolute_error: 0.0890\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01572\n",
      "No alternative save happened on for epoch 22\n",
      "Epoch 24/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0090 - mean_absolute_error: 0.0684 - val_loss: 0.0173 - val_mean_absolute_error: 0.0875\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01572\n",
      "No alternative save happened on for epoch 23\n",
      "Epoch 25/100\n",
      "1862/1862 [==============================] - 13s 7ms/step - loss: 0.0089 - mean_absolute_error: 0.0682 - val_loss: 0.0156 - val_mean_absolute_error: 0.0807\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01572 to 0.01559, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 24 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0156.\n",
      "Epoch 26/100\n",
      "1862/1862 [==============================] - 18s 9ms/step - loss: 0.0090 - mean_absolute_error: 0.0688 - val_loss: 0.0154 - val_mean_absolute_error: 0.0808\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01559 to 0.01538, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 25 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0154.\n",
      "Epoch 27/100\n",
      "1862/1862 [==============================] - 16s 9ms/step - loss: 0.0089 - mean_absolute_error: 0.0681 - val_loss: 0.0138 - val_mean_absolute_error: 0.0747\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01538 to 0.01377, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 26 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0138.\n",
      "Epoch 28/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0089 - mean_absolute_error: 0.0677 - val_loss: 0.0152 - val_mean_absolute_error: 0.0803\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 27\n",
      "Epoch 29/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0089 - mean_absolute_error: 0.0675 - val_loss: 0.0153 - val_mean_absolute_error: 0.0798\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 28\n",
      "Epoch 30/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0087 - mean_absolute_error: 0.0673 - val_loss: 0.0151 - val_mean_absolute_error: 0.0814\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 29\n",
      "Epoch 31/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0085 - mean_absolute_error: 0.0661 - val_loss: 0.0155 - val_mean_absolute_error: 0.0816\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 30\n",
      "Epoch 32/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0085 - mean_absolute_error: 0.0659 - val_loss: 0.0143 - val_mean_absolute_error: 0.0761\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 31\n",
      "Epoch 33/100\n",
      "1862/1862 [==============================] - 16s 9ms/step - loss: 0.0083 - mean_absolute_error: 0.0656 - val_loss: 0.0154 - val_mean_absolute_error: 0.0796\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 32\n",
      "Epoch 34/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0084 - mean_absolute_error: 0.0658 - val_loss: 0.0153 - val_mean_absolute_error: 0.0794\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 33\n",
      "Epoch 35/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0084 - mean_absolute_error: 0.0655 - val_loss: 0.0157 - val_mean_absolute_error: 0.0807\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 34\n",
      "Epoch 36/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0083 - mean_absolute_error: 0.0653 - val_loss: 0.0138 - val_mean_absolute_error: 0.0737\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01377 to 0.01377, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 35 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0138.\n",
      "Epoch 37/100\n",
      "1862/1862 [==============================] - 16s 9ms/step - loss: 0.0083 - mean_absolute_error: 0.0650 - val_loss: 0.0146 - val_mean_absolute_error: 0.0771\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 36\n",
      "Epoch 38/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0084 - mean_absolute_error: 0.0653 - val_loss: 0.0147 - val_mean_absolute_error: 0.0786\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 37\n",
      "Epoch 39/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0082 - mean_absolute_error: 0.0646 - val_loss: 0.0163 - val_mean_absolute_error: 0.0821\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 38\n",
      "Epoch 40/100\n",
      "1862/1862 [==============================] - 18s 9ms/step - loss: 0.0081 - mean_absolute_error: 0.0643 - val_loss: 0.0142 - val_mean_absolute_error: 0.0765\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 39\n",
      "Epoch 41/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0082 - mean_absolute_error: 0.0645 - val_loss: 0.0146 - val_mean_absolute_error: 0.0784\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 40\n",
      "Epoch 42/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0081 - mean_absolute_error: 0.0640 - val_loss: 0.0156 - val_mean_absolute_error: 0.0806\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 41\n",
      "Epoch 43/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0081 - mean_absolute_error: 0.0638 - val_loss: 0.0148 - val_mean_absolute_error: 0.0784\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01377\n",
      "No alternative save happened on for epoch 42\n",
      "Epoch 44/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0080 - mean_absolute_error: 0.0636 - val_loss: 0.0134 - val_mean_absolute_error: 0.0721\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01377 to 0.01339, saving model to data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\n",
      "Alternative save happened on for epoch 43 happened on data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle for val_loss of 0.0134.\n",
      "Epoch 45/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0080 - mean_absolute_error: 0.0636 - val_loss: 0.0154 - val_mean_absolute_error: 0.0796\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 44\n",
      "Epoch 46/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0078 - mean_absolute_error: 0.0629 - val_loss: 0.0141 - val_mean_absolute_error: 0.0746\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 45\n",
      "Epoch 47/100\n",
      "1862/1862 [==============================] - 16s 8ms/step - loss: 0.0080 - mean_absolute_error: 0.0634 - val_loss: 0.0137 - val_mean_absolute_error: 0.0731\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 46\n",
      "Epoch 48/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0078 - mean_absolute_error: 0.0627 - val_loss: 0.0147 - val_mean_absolute_error: 0.0764\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 47\n",
      "Epoch 49/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0625 - val_loss: 0.0137 - val_mean_absolute_error: 0.0726\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 48\n",
      "Epoch 50/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0076 - mean_absolute_error: 0.0622 - val_loss: 0.0153 - val_mean_absolute_error: 0.0792\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 49\n",
      "Epoch 51/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0622 - val_loss: 0.0150 - val_mean_absolute_error: 0.0772\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 50\n",
      "Epoch 52/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0621 - val_loss: 0.0147 - val_mean_absolute_error: 0.0763\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 51\n",
      "Epoch 53/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0078 - mean_absolute_error: 0.0627 - val_loss: 0.0144 - val_mean_absolute_error: 0.0753\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 52\n",
      "Epoch 54/100\n",
      "1862/1862 [==============================] - 17s 9ms/step - loss: 0.0077 - mean_absolute_error: 0.0620 - val_loss: 0.0142 - val_mean_absolute_error: 0.0758\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.01339\n",
      "No alternative save happened on for epoch 53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3b13ebf190>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' time for some model training '''\n",
    "\n",
    "my_trainer = DLTrainer(max_epochs=MAX_EPOCHS, patience=PATIENCE)\n",
    "my_trainer.LSTM_one_shot_predictor_named_i(my_ds, LSTM_LAYER_SIZE, DENSE_LAYER_SIZE, \n",
    "NUM_LSTM_LAYERS, NUM_DENSE_LAYERS, extra_features=['all_destinations'], \n",
    "var_time_len=VARIABLE_INPUT_LENGTH, size_dict=my_ds.size_dict)\n",
    "\n",
    "from datetime import datetime \n",
    "\n",
    "folder_path = \"data/model_weights/checkpoints/%s\" % (datetime.now().strftime(\"%d_%m_%Y__%H_%M\"))\n",
    "save_path = os.path.join(folder_path, \"model_3_4_w_dests_sdd.pickle\")            \n",
    "if not os.path.exists(folder_path):\n",
    "    os.mkdir(folder_path)\n",
    "my_trainer.compile_and_fit2(my_ds.tf_ds_dict[\"train\"], my_ds.tf_ds_dict[\"val\"], save_path=save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the 2 models (with and without destination included as a feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 3, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='flatten_7/Reshape:0', description=\"created by layer 'flatten_7'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 9, 3), dtype=tf.float32, name='all_destinations'), name='all_destinations', description=\"created by layer 'all_destinations'\")\n",
      "3\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 3, 2), dtype=tf.float32, name='in_xy'), name='in_xy', description=\"created by layer 'in_xy'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name=None), name='flatten_9/Reshape:0', description=\"created by layer 'flatten_9'\")\n"
     ]
    }
   ],
   "source": [
    "''' or some model loading '''\n",
    "\n",
    "# first with destinations\n",
    "model_path = \"data/model_weights/checkpoints/11_10_2021__23_02/model_3_4_w_dests_sdd.pickle\"\n",
    "\n",
    "my_trainer_w_dest = DLTrainer(max_epochs=MAX_EPOCHS, patience=PATIENCE)\n",
    "my_trainer_w_dest.LSTM_one_shot_predictor_named_i(my_ds, 32, 32, \n",
    "NUM_LSTM_LAYERS, NUM_DENSE_LAYERS, extra_features=[\"all_destinations\"], \n",
    "var_time_len=VARIABLE_INPUT_LENGTH, size_dict=my_ds.size_dict, epistemic=False, dropout_rate=0.05)\n",
    "my_trainer_w_dest.load_weights(model_path)\n",
    "\n",
    "# and also one without destinations\n",
    "model_path = \"data/model_weights/checkpoints/11_10_2021__22_22/model_3_4_wo_dests_sdd.pickle\"\n",
    "\n",
    "my_trainer_wo_dest = DLTrainer(max_epochs=MAX_EPOCHS, patience=PATIENCE)\n",
    "my_trainer_wo_dest.LSTM_one_shot_predictor_named_i(my_ds, 32, 32, \n",
    "NUM_LSTM_LAYERS, NUM_DENSE_LAYERS, extra_features=[], \n",
    "var_time_len=VARIABLE_INPUT_LENGTH, size_dict=my_ds.size_dict, epistemic=False, dropout_rate=0.05)\n",
    "my_trainer_wo_dest.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "547it [20:32,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With destination: [17.853980063093395, 17.152611579018213, 25.373647371730687, 16.74323386948167, 19.45001740837194, 15.610221554363267, 13.456024060632982, 21.87390619021967, 22.17893098503176]\n",
      "Without destination: [19.419836652833276, 18.02128269776322, 20.397181625435397, 22.875803758629104, 21.411840887570733, 18.045361897161893, 15.10982915499526, 21.98991947654668, 17.965376838313777]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "''' Calculate KPIs for the whole test data set '''\n",
    "# set up values where \n",
    "num_predicted_batches = 0.\n",
    "total_w_dest = [0.] * len(g.destination_names)\n",
    "total_wo_dest = [0.] * len(g.destination_names)\n",
    "\n",
    "test_ds = my_ds.tf_ds_dict[\"test\"]\n",
    "\n",
    "for batch in tqdm(iter(test_ds)):\n",
    "    batch_in = batch[0]\n",
    "    batch_out = batch[1]\n",
    "\n",
    "    # predict without destination\n",
    "    pred_wo_dest = my_trainer_wo_dest.predict_repetitively_dict(batch_in, False, 25, False)\n",
    "\n",
    "    for dest_name in g.destination_names:\n",
    "        dest_loc = g.dest_dict[dest_name]\n",
    "\n",
    "        # get one hot vector to dest\n",
    "        dest_index = g.destinations_indices_dict[dest_name]\n",
    "        min_dest_index = min(g.destinations_indices_dict.values())\n",
    "\n",
    "        new_probs = tf.one_hot(\n",
    "            [dest_index-min_dest_index], g.num_destinations, on_value=None, off_value=None, axis=None, dtype=tf.float32, name=None\n",
    "        )\n",
    "        new_probs = tf.reshape(new_probs, [-1, 1])\n",
    "\n",
    "        in_shape = batch_in[\"in_xy\"].shape\n",
    "        if len(in_shape)==2:\n",
    "            batch_size = 1\n",
    "        else: \n",
    "            batch_size = in_shape[-3]\n",
    "        probs_lst = [new_probs for i in range(batch_size)]\n",
    "        new_probs=tf.stack(probs_lst)\n",
    "\n",
    "        # implement the one hot vector\n",
    "        input_dict_c = dict(batch_in)\n",
    "        dest_loc_one_hot = tf.concat([input_dict_c[\"all_destinations\"][:,:,0:2], new_probs], axis=-1)\n",
    "        input_dict_c[\"all_destinations\"] = dest_loc_one_hot\n",
    "\n",
    "        # print(dest_index)\n",
    "        # print(dest_loc_one_hot)\n",
    "\n",
    "        # do prediction with destination\n",
    "        pred_w_dest = my_trainer_w_dest.predict_repetitively_dict(input_dict_c, False, 27, False)\n",
    "        \n",
    "        # now do kpi calculation\n",
    "        kpi_w_dest = destination_distance_l(pred_w_dest, dest_loc, only_endpoint=False)\n",
    "        kpi_wo_dest = destination_distance_l(pred_wo_dest, dest_loc, only_endpoint=False)\n",
    "        \n",
    "        # print(pred_w_dest[:, :-1, :])\n",
    "        # print(pred_wo_dest[:, :-1, :])\n",
    "        # print(\"With destination: %s\"%np.average(kpi_w_dest))\n",
    "        # print(\"Without destination: %s\"%np.average(kpi_wo_dest))\n",
    "\n",
    "        total_w_dest[dest_index-min_dest_index] += np.sum(kpi_w_dest) / np.max(kpi_w_dest.shape)\n",
    "        total_wo_dest[dest_index-min_dest_index] += np.sum(kpi_wo_dest) / np.max(kpi_w_dest.shape)\n",
    "\n",
    "    num_predicted_batches += 1\n",
    "\n",
    "    # if num_predicted_batches > 20:\n",
    "    #     break\n",
    "\n",
    "print(\"With destination: %s\"%[el/num_predicted_batches for el in total_w_dest])\n",
    "print(\"Without destination: %s\"%[el/num_predicted_batches for el in total_wo_dest])\n",
    "\n",
    "\n",
    "    \n",
    "    # print(\"With destination: %s\"%(total_w_dest/num_predictions))\n",
    "    # print(\"Without destination: %s\"%(total_wo_dest/num_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' time for some model predictions '''\n",
    "my_predictor_w_dest = extended_predictor(g, my_trainer_w_dest, 1)\n",
    "\n",
    "nxt_unsc, nxt_sc = my_ds.example_dict(\"test\", \"in_xy\")\n",
    "\n",
    "# Let's extract just one path to make visualisation clearer\n",
    "unscaled_ex = dict(nxt_unsc[0]), nxt_unsc[1]\n",
    "scaled_ex = dict(nxt_sc[0]), nxt_sc[1]\n",
    "# let's get an example of length one\n",
    "for key in unscaled_ex[0].keys():\n",
    "    unscaled_ex[0][key] = tf.expand_dims(nxt_unsc[0][key][0], axis=0)\n",
    "for key in scaled_ex[0].keys():\n",
    "    scaled_ex[0][key] = tf.expand_dims(nxt_sc[0][key][0], axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic prediction, but repeated (one at a time)\n",
    "#PROBLEM: input is scaled\n",
    "assembled_output, destination_list, dest_prob_dict = my_predictor_w_dest.predict_to_destinations(input_dict=unscaled_ex[0], \n",
    "num_steps = 20, variable_len_input=VARIABLE_INPUT_LENGTH, num_predictions=15, norm_probs=True, abs_probs=False)\n",
    "# Epistemic uncertainty prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find how many paths are within range of 4 meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c2d8a65fca09951dc659d1e5be9936e2934486deb85c70863d4e61586159541"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('thesis_basic': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
